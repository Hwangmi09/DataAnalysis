{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_텍스트 _전처리.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VicRPp1w7wpa"
      },
      "source": [
        "# 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNqa3H2r70LZ"
      },
      "source": [
        "## 6. 정수 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaWBzAV8Dx-"
      },
      "source": [
        "### 1) Counter 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhWdSrTM7iGU"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w79x0zU68P8X"
      },
      "source": [
        "sentences = [\n",
        "    ['barber', 'person'], \n",
        "    ['barber', 'good', 'person'], \n",
        "    ['barber', 'huge', 'person'], \n",
        "    ['knew', 'secret'],\n",
        "    ['secret', 'kept', 'huge', 'secret'], \n",
        "    ['huge', 'secret'], \n",
        "    ['barber', 'kept', 'word'], \n",
        "    ['barber', 'kept', 'word'], \n",
        "    ['barber', 'kept', 'secret'], \n",
        "    ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
        "    ['barber', 'went', 'huge', 'mountain']\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6IvKTv3_RHA",
        "outputId": "bb6a4293-73f4-41c2-e7dc-014505ec4ec7"
      },
      "source": [
        "words = sum(sentences, []) #  [ ]를 제거하고 단어들을 하나의 리스트로\n",
        "print(words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw5eHGbS_ZJ_",
        "outputId": "bffd72ca-7da6-4bd2-d537-98daeaa121ab"
      },
      "source": [
        "vocab = Counter(words) # 중복을 제거하고 단어의 빈도수를 기록\n",
        "vocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'barber': 8,\n",
              "         'crazy': 1,\n",
              "         'driving': 1,\n",
              "         'good': 1,\n",
              "         'huge': 5,\n",
              "         'keeping': 2,\n",
              "         'kept': 4,\n",
              "         'knew': 1,\n",
              "         'mountain': 1,\n",
              "         'person': 3,\n",
              "         'secret': 6,\n",
              "         'went': 1,\n",
              "         'word': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4lCIeyD_dNY",
        "outputId": "4b5b92d6-3b29-4d35-c34f-94b90a6539a7"
      },
      "source": [
        "vocab.most_common(5) # 상위 빈도수를 가진 주어진 수의 단어만을 리턴"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNweoK0H_y6v",
        "outputId": "eb965ba9-cdff-49df-fd60-ac5d5266f795"
      },
      "source": [
        "top5 = vocab.most_common(5)\n",
        "top5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndt8lik7AFjV",
        "outputId": "6753fa3d-5dfd-4883-ae77-77137ceb6de4"
      },
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for word, freq in top5:\n",
        "    i += 1\n",
        "    word_to_index[word] = i # 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여\n",
        "word_to_index "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'kept': 4, 'person': 5, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGb16vY0BVBZ"
      },
      "source": [
        "### 2) NLTK의 FreqDist 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aJE4cCPA0gK"
      },
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS4h9r-sBo-y"
      },
      "source": [
        "vocab = FreqDist(words) # 빈도수 계산"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqd7RoMcBroI",
        "outputId": "6df3983d-2fc6-4f13-aa78-2b1f19f3e01d"
      },
      "source": [
        "vocab['barber']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDSY-dynBxSD",
        "outputId": "596c4865-95cf-4896-b960-7885d311a2d9"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'barber': 8,\n",
              "          'crazy': 1,\n",
              "          'driving': 1,\n",
              "          'good': 1,\n",
              "          'huge': 5,\n",
              "          'keeping': 2,\n",
              "          'kept': 4,\n",
              "          'knew': 1,\n",
              "          'mountain': 1,\n",
              "          'person': 3,\n",
              "          'secret': 6,\n",
              "          'went': 1,\n",
              "          'word': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc2ADDCaBzPR",
        "outputId": "f269d9cc-b7ea-44fa-fb25-0bc5413125a3"
      },
      "source": [
        "top5 = vocab.most_common(5)\n",
        "top5"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqQai1rTCcJc",
        "outputId": "480d6fc5-7e9d-4f9c-f90d-f9303b97b0c4"
      },
      "source": [
        "word_to_index = {word[0] : i+1 for i, word in enumerate(top5)}\n",
        "word_to_index"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'kept': 4, 'person': 5, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwmcsrJaDslB"
      },
      "source": [
        "### 3) Keras 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1b3qzMeDPVC"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u_MK8bYF6Qv",
        "outputId": "8aa0191d-b5a6-45c6-d737-6857a0e47df0"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences) # 입력한 텍스트로부터 단어 빈도수가 높은 순으로 낮은 정수 인덱스를 부여\n",
        "tokenizer.word_index # 각 단어에 인덱스가 어떻게 부여되었는지를 보려면, word_index를 사용"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1,\n",
              " 'crazy': 11,\n",
              " 'driving': 10,\n",
              " 'good': 8,\n",
              " 'huge': 3,\n",
              " 'keeping': 7,\n",
              " 'kept': 4,\n",
              " 'knew': 9,\n",
              " 'mountain': 13,\n",
              " 'person': 5,\n",
              " 'secret': 2,\n",
              " 'went': 12,\n",
              " 'word': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1rG43uPGAU4",
        "outputId": "8549aa0a-7838-419d-e4ab-474d25bae689"
      },
      "source": [
        "tokenizer.word_counts # 각 단어가 카운트를 수행하였을 때 몇 개였는지를 보고자 한다면 word_counts를 사용"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('barber', 8),\n",
              "             ('person', 3),\n",
              "             ('good', 1),\n",
              "             ('huge', 5),\n",
              "             ('knew', 1),\n",
              "             ('secret', 6),\n",
              "             ('kept', 4),\n",
              "             ('word', 2),\n",
              "             ('keeping', 2),\n",
              "             ('driving', 1),\n",
              "             ('crazy', 1),\n",
              "             ('went', 1),\n",
              "             ('mountain', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSUNdFloGXrV",
        "outputId": "d2c2e7c8-c9e1-4213-e9af-ac3c62328b8f"
      },
      "source": [
        "tokenizer.texts_to_sequences(sentences) #  입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 5],\n",
              " [1, 8, 5],\n",
              " [1, 3, 5],\n",
              " [9, 2],\n",
              " [2, 4, 3, 2],\n",
              " [3, 2],\n",
              " [1, 4, 6],\n",
              " [1, 4, 6],\n",
              " [1, 4, 2],\n",
              " [7, 7, 3, 2, 10, 1, 11],\n",
              " [1, 12, 3, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9udD1YyRINy0"
      },
      "source": [
        "- 단어 빈도수 Top 5만 제대로 표시하고, 나머지는 OOV 값(1)으로 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z9WmXBGG9fW"
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV') # 빈도수가 높은 상위 몇 개의 단어만 사용하겠다고 지정\n",
        "# num_words는 숫자를 0부터 카운트\n",
        "# 단어 집합에 없는 단어인 OOV\n",
        "# 단어 집합에 없는 단어들은 OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용\n",
        "# 빈도수 상위 5개 단어만 사용. 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
        "# oov_token을 사용하기로 했다면 케라스 토크나이저는 기본적으로 'OOV'의 인덱스를 1로 함.\n",
        "tokenizer.fit_on_texts(sentences) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4ikXVV9OruM",
        "outputId": "43086d3c-ab98-4bf9-bbb8-8c037ffc158f"
      },
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy24YnKuHweQ",
        "outputId": "9e4744be-834f-427e-ad15-0ad4f0d612d4"
      },
      "source": [
        "tokenizer.texts_to_sequences(sentences) # 실제 적용은 texts_to_sequences를 사용할 때 적용"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 6],\n",
              " [2, 1, 6],\n",
              " [2, 4, 6],\n",
              " [1, 3],\n",
              " [3, 5, 4, 3],\n",
              " [4, 3],\n",
              " [2, 5, 1],\n",
              " [2, 5, 1],\n",
              " [2, 5, 3],\n",
              " [1, 1, 4, 3, 1, 2, 1],\n",
              " [2, 1, 4, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssQgR09HxwA",
        "outputId": "317bdf88-12d5-4d0c-b10f-a9390ed973aa"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'OOV': 1,\n",
              " 'barber': 2,\n",
              " 'crazy': 12,\n",
              " 'driving': 11,\n",
              " 'good': 9,\n",
              " 'huge': 4,\n",
              " 'keeping': 8,\n",
              " 'kept': 5,\n",
              " 'knew': 10,\n",
              " 'mountain': 14,\n",
              " 'person': 6,\n",
              " 'secret': 3,\n",
              " 'went': 13,\n",
              " 'word': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHqI9uZtJB1t"
      },
      "source": [
        "## 7. 패딩(Padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQtWq9cFJF0i",
        "outputId": "e4316c85-e685-43ef-e755-bd411e9b53ef"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print(encoded)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar5mTA6_NLXr",
        "outputId": "f3f2ac6d-a4e6-47e6-f019-5c37f91a6a87"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_sequences(encoded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 2, 6],\n",
              "       [0, 0, 0, 0, 2, 1, 6],\n",
              "       [0, 0, 0, 0, 2, 4, 6],\n",
              "       [0, 0, 0, 0, 0, 1, 3],\n",
              "       [0, 0, 0, 3, 5, 4, 3],\n",
              "       [0, 0, 0, 0, 0, 4, 3],\n",
              "       [0, 0, 0, 0, 2, 5, 1],\n",
              "       [0, 0, 0, 0, 2, 5, 1],\n",
              "       [0, 0, 0, 0, 2, 5, 3],\n",
              "       [1, 1, 4, 3, 1, 2, 1],\n",
              "       [0, 0, 0, 2, 1, 4, 1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIjGe2OnNUxn",
        "outputId": "7f7cd67b-b336-4bf2-9679-66688a50c19e"
      },
      "source": [
        "pad_sequences(encoded, padding='post')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 6, 0, 0, 0, 0, 0],\n",
              "       [2, 1, 6, 0, 0, 0, 0],\n",
              "       [2, 4, 6, 0, 0, 0, 0],\n",
              "       [1, 3, 0, 0, 0, 0, 0],\n",
              "       [3, 5, 4, 3, 0, 0, 0],\n",
              "       [4, 3, 0, 0, 0, 0, 0],\n",
              "       [2, 5, 1, 0, 0, 0, 0],\n",
              "       [2, 5, 1, 0, 0, 0, 0],\n",
              "       [2, 5, 3, 0, 0, 0, 0],\n",
              "       [1, 1, 4, 3, 1, 2, 1],\n",
              "       [2, 1, 4, 1, 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgSxwU_gOT6v",
        "outputId": "cc48b38a-bcc0-48c6-f954-c78523758e94"
      },
      "source": [
        "# 실전에서 사용하는 방법\n",
        "pad_sequences(encoded, padding='post', maxlen=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 6, 0, 0, 0],\n",
              "       [2, 1, 6, 0, 0],\n",
              "       [2, 4, 6, 0, 0],\n",
              "       [1, 3, 0, 0, 0],\n",
              "       [3, 5, 4, 3, 0],\n",
              "       [4, 3, 0, 0, 0],\n",
              "       [2, 5, 1, 0, 0],\n",
              "       [2, 5, 1, 0, 0],\n",
              "       [2, 5, 3, 0, 0],\n",
              "       [4, 3, 1, 2, 1],\n",
              "       [2, 1, 4, 1, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjoUTmljPf-i"
      },
      "source": [
        "## 8. 원-핫 인코딩(One-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iyxRGWmQ2jZ"
      },
      "source": [
        "!pip install konlpy > /dev/null"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNEcK9sTO1_B",
        "outputId": "6a02afe6-6f1a-4dda-850e-7fa6cadbcd03"
      },
      "source": [
        "from  konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = '나는 자연어 처리를 배운다'\n",
        "token = okt.morphs(text)\n",
        "token"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나', '는', '자연어', '처리', '를', '배운다']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quC0UzbbRKMI",
        "outputId": "46635914-d894-48f0-f90c-0b31ac5ecc2e"
      },
      "source": [
        "word_to_index = {word: i for i, word in enumerate(token)}\n",
        "word_to_index"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'나': 0, '는': 1, '를': 4, '배운다': 5, '자연어': 2, '처리': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QshvrrChR6NU",
        "outputId": "13287316-f33e-487d-d9e5-13704e83028f"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "to_categorical(list(word_to_index.values()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGFsNU_gSKMx",
        "outputId": "d18e8a8d-73b1-412c-90a4-0a0373b5c51e"
      },
      "source": [
        "text=\"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts([text])\n",
        "print(t.word_index) # 각 단어에 대한 인코딩 결과 출력."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Rep-w3Sz9i",
        "outputId": "b425a2e3-3068-47cd-a476-2ab8dc6347f7"
      },
      "source": [
        "encoded=t.texts_to_sequences([text])[0]\n",
        "encoded"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 2, 5, 1, 2, 6, 3, 1, 1, 3, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdBgxhuwTCF4",
        "outputId": "bc10ce08-0aec-4ac8-daf1-99b1b1d30d8d"
      },
      "source": [
        "to_categorical(encoded)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob98DmyCTH55"
      },
      "source": [
        "# 원-핫 인코딩의 한계\n",
        "# 단어의 개수가 늘어날 수록, 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점\n",
        "# 단어의 유사도를 표현하지 못한다는 단점\n",
        "# 이러한 단점을 해결하기 위해 단어의 잠재 의미를 반영하여 다차원 공간에 벡터화 하는 기법 : 카운트 기반과 예측 기반 두 가지 방법"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWNuIyxMUgpr"
      },
      "source": [
        "## 9. 데이터의 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKy-ocr6Ujs5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP-k__dPX6p4"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iR6v4GKYGcL",
        "outputId": "de1618b6-3b94-44f6-b174-2d19b18c3289"
      },
      "source": [
        "iris.data[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j4Hn35rYKqn",
        "outputId": "9ed100ae-d035-4220-a062-60be41c6bbe5"
      },
      "source": [
        "iris.target[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIQtnUS8atfc",
        "outputId": "2cb68622-4cd9-4cbc-f7d7-63567e313a11"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtXS9NuGXg4m",
        "outputId": "a9e48294-fdeb-40c6-c07f-c3d93a65a4ca"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.2, random_state=2021\n",
        ")\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (30, 4), (120,), (30,))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umon-nSRbBuW",
        "outputId": "4ae42eee-d5f8-484b-ebb9-0a061df54720"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 0 0 0 0 0 0 1 2 2 1 2 1 1 0 1 1 2 2 0 2 1 1 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFw5ouCYb9kH",
        "outputId": "e31c3ecc-fd60-4ae7-b49d-d526b87626d1"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([14, 10,  6]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE-mi9KTbb0r"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, stratify=iris.target, test_size=0.2, random_state=2021 # stratify=iris.target\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFBX0745bl-v",
        "outputId": "5cf52b4b-2039-460c-a961-3aa316501250"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 2 0 1 0 1 2 0 1 1 1 2 2 0 2 0 2 0 1 2 0 2 2 0 1 1 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGJqHIs_bxdq",
        "outputId": "bfa7a1b1-20e9-4ab7-915a-4e5a045e9e58"
      },
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([10, 10, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}